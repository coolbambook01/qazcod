{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb792c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD : /Users/dana/Desktop/qazcode/qazcode-nu/data\n",
      "ROOT: /Users/dana/Desktop/qazcode/qazcode-nu\n",
      "DATA: /Users/dana/Desktop/qazcode/qazcode-nu/data/test_set\n",
      "Loaded records: 221\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    for p in [Path.cwd(), *Path.cwd().parents]:\n",
    "        if (p / \"data\" / \"test_set\").is_dir():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Could not find data/test_set from current working directory.\")\n",
    "\n",
    "ROOT = find_project_root()\n",
    "DATA_DIR = ROOT / \"data\" / \"test_set\"\n",
    "\n",
    "print(\"CWD :\", Path.cwd())\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA:\", DATA_DIR)\n",
    "\n",
    "records = []\n",
    "for p in sorted(DATA_DIR.glob(\"*.json\")):\n",
    "    records.append(json.loads(p.read_text(encoding=\"utf-8\")))\n",
    "\n",
    "print(\"Loaded records:\", len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8de70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-empty raw queries: 220\n",
      "Non-empty normalized: 220\n",
      "Example normalized: здравствуйте пару недель назад неудачно упала спину верхней ступеньки лестницы съехала ударилась примерно между лопатками подумала что ушиб боль проходит даже наоборот середине спины жгуче ноет тянет \n"
     ]
    }
   ],
   "source": [
    "TOKEN_RE = re.compile(r\"[a-zа-я0-9]+\", re.IGNORECASE)\n",
    "\n",
    "def normalize_text(text: Any) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    toks = (t.lower() for t in TOKEN_RE.findall(text))\n",
    "    toks = [t for t in toks if len(t) > 2]  # no stopwords (safer)\n",
    "    return \" \".join(toks)\n",
    "\n",
    "texts_norm = [normalize_text(r.get(\"query\",\"\")) for r in records]\n",
    "\n",
    "print(\"Non-empty raw queries:\", sum(1 for r in records if (r.get(\"query\") or \"\").strip()))\n",
    "print(\"Non-empty normalized:\", sum(1 for t in texts_norm if t.strip()))\n",
    "print(\"Example normalized:\", (texts_norm[0][:200] if records else \"no records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f45453a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF built: (221, 21558) (221, 28197)\n"
     ]
    }
   ],
   "source": [
    "raw_texts = [(r.get(\"query\") or \"\") for r in records]\n",
    "\n",
    "# fallback: if normalization makes text empty, use raw\n",
    "texts = []\n",
    "for raw in raw_texts:\n",
    "    t = normalize_text(raw)\n",
    "    texts.append(t if t.strip() else raw)\n",
    "\n",
    "doc_gt = [str(r.get(\"gt\",\"\")) for r in records]\n",
    "doc_valid = [set(r.get(\"icd_codes\", [])) for r in records]\n",
    "\n",
    "word_vec = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    min_df=1,\n",
    "    max_features=80_000,\n",
    "    sublinear_tf=True,\n",
    "    lowercase=True,\n",
    ")\n",
    "\n",
    "char_vec = TfidfVectorizer(\n",
    "    analyzer=\"char_wb\",\n",
    "    ngram_range=(3,5),\n",
    "    min_df=1,\n",
    "    max_features=120_000,\n",
    "    sublinear_tf=True,\n",
    "    lowercase=True,\n",
    ")\n",
    "\n",
    "word_X = word_vec.fit_transform(texts)\n",
    "char_X = char_vec.fit_transform(texts)\n",
    "\n",
    "print(\"TF-IDF built:\", word_X.shape, char_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81d0115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval subset size: 30 seed: 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_codes</th>\n",
       "      <th>k_neighbors</th>\n",
       "      <th>alpha</th>\n",
       "      <th>n</th>\n",
       "      <th>acc1_%</th>\n",
       "      <th>recall3_%</th>\n",
       "      <th>lat_avg_ms</th>\n",
       "      <th>lat_p95_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>0.65</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.65</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>0.65</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>0.75</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>0.65</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>0.65</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>0.75</td>\n",
       "      <td>30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>96.67</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    top_codes  k_neighbors  alpha   n  acc1_%  recall3_%  lat_avg_ms  \\\n",
       "0          15           40   0.65  30    6.67      96.67         1.5   \n",
       "1          15           40   0.75  30    6.67      96.67         1.5   \n",
       "2          30           40   0.55  30    6.67      96.67         1.5   \n",
       "3          30           40   0.65  30    6.67      96.67         1.5   \n",
       "4          30           40   0.75  30    6.67      96.67         1.5   \n",
       "5          50           40   0.55  30    6.67      96.67         1.5   \n",
       "6          15           60   0.55  30    6.67      96.67         1.6   \n",
       "7          15           60   0.65  30    6.67      96.67         1.6   \n",
       "8          15           60   0.75  30    6.67      96.67         1.6   \n",
       "9          15           80   0.55  30    6.67      96.67         1.6   \n",
       "10         15           80   0.65  30    6.67      96.67         1.6   \n",
       "11         15           80   0.75  30    6.67      96.67         1.6   \n",
       "12         30           60   0.55  30    6.67      96.67         1.6   \n",
       "13         30           60   0.65  30    6.67      96.67         1.6   \n",
       "14         30           60   0.75  30    6.67      96.67         1.6   \n",
       "\n",
       "    lat_p95_ms  \n",
       "0          1.8  \n",
       "1          1.7  \n",
       "2          1.8  \n",
       "3          1.7  \n",
       "4          1.8  \n",
       "5          1.8  \n",
       "6          1.8  \n",
       "7          2.0  \n",
       "8          1.8  \n",
       "9          1.9  \n",
       "10         1.9  \n",
       "11         1.9  \n",
       "12         1.8  \n",
       "13         1.8  \n",
       "14         1.8  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_codes(symptoms: str, top_codes: int, k_neighbors: int, alpha: float) -> list[str]:\n",
    "    t = normalize_text(symptoms)\n",
    "    if not t.strip():\n",
    "        freq = Counter(doc_gt)\n",
    "        return [c for c, _ in freq.most_common(top_codes) if c]\n",
    "\n",
    "    qw = word_vec.transform([t])\n",
    "    qc = char_vec.transform([t])\n",
    "\n",
    "    sw = (word_X @ qw.T).toarray().ravel()\n",
    "    sc = (char_X @ qc.T).toarray().ravel()\n",
    "    s = alpha * sw + (1.0 - alpha) * sc\n",
    "\n",
    "    k = min(k_neighbors, len(s))\n",
    "    idx = np.argpartition(-s, k - 1)[:k]\n",
    "    idx = idx[np.argsort(-s[idx])]\n",
    "\n",
    "    code_score = defaultdict(float)\n",
    "    for rank, i in enumerate(idx, start=1):\n",
    "        w = float(s[i]) / rank\n",
    "        codes = doc_valid[i] if doc_valid[i] else {doc_gt[i]}\n",
    "        for code in codes:\n",
    "            code = str(code).strip()\n",
    "            if code:\n",
    "                code_score[code] += w\n",
    "\n",
    "    best = sorted(code_score.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [c for c, _ in best[:top_codes]] if best else []\n",
    "\n",
    "\n",
    "def eval_config(subset, *, top_codes: int, k_neighbors: int, alpha: float) -> dict:\n",
    "    acc1 = 0\n",
    "    rec3 = 0\n",
    "    lat = []\n",
    "\n",
    "    for r in subset:\n",
    "        symptoms = r.get(\"query\", \"\")\n",
    "        gt = str(r.get(\"gt\", \"\"))\n",
    "        valid = set(r.get(\"icd_codes\", []))\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        preds = retrieve_codes(symptoms, top_codes=top_codes, k_neighbors=k_neighbors, alpha=alpha)\n",
    "        lat.append(time.perf_counter() - t0)\n",
    "\n",
    "        top3 = preds[:3]\n",
    "        if top3 and top3[0] == gt:\n",
    "            acc1 += 1\n",
    "        if any(c in valid for c in top3):\n",
    "            rec3 += 1\n",
    "\n",
    "    n = len(subset) or 1\n",
    "    lat_sorted = sorted(lat)\n",
    "    p95 = lat_sorted[int(0.95 * (len(lat_sorted) - 1))] if lat_sorted else None\n",
    "\n",
    "    return {\n",
    "        \"top_codes\": top_codes,\n",
    "        \"k_neighbors\": k_neighbors,\n",
    "        \"alpha\": alpha,\n",
    "        \"n\": len(subset),\n",
    "        \"acc1_%\": round(100 * acc1 / n, 2),\n",
    "        \"recall3_%\": round(100 * rec3 / n, 2),\n",
    "        \"lat_avg_ms\": round(1000 * statistics.mean(lat), 1) if lat else None,\n",
    "        \"lat_p95_ms\": round(1000 * p95, 1) if p95 is not None else None,\n",
    "    }\n",
    "\n",
    "\n",
    "# pick random 30\n",
    "seed = 42\n",
    "rng = random.Random(seed)\n",
    "subset = records[:]\n",
    "rng.shuffle(subset)\n",
    "subset = subset[:min(30, len(subset))]\n",
    "print(\"Eval subset size:\", len(subset), \"seed:\", seed)\n",
    "\n",
    "TOP_CODES_GRID = [15, 30, 50]\n",
    "KNN_GRID = [40, 60, 80, 120]\n",
    "ALPHA_GRID = [0.55, 0.65, 0.75]\n",
    "\n",
    "rows = []\n",
    "for top_codes in TOP_CODES_GRID:\n",
    "    for k_neighbors in KNN_GRID:\n",
    "        for alpha in ALPHA_GRID:\n",
    "            rows.append(eval_config(subset, top_codes=top_codes, k_neighbors=k_neighbors, alpha=alpha))\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\n",
    "    by=[\"recall3_%\", \"acc1_%\", \"lat_avg_ms\"],\n",
    "    ascending=[False, False, True],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec14f2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: 30 seed: 123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>n</th>\n",
       "      <th>acc1_%</th>\n",
       "      <th>recall3_%</th>\n",
       "      <th>lat_avg_ms</th>\n",
       "      <th>lat_p95_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.30</td>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.10</td>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beta   n  acc1_%  recall3_%  lat_avg_ms  lat_p95_ms\n",
       "0  0.15  30   100.0      100.0        1.55        1.69\n",
       "1  0.30  30   100.0      100.0        1.55        1.73\n",
       "2  0.40  30   100.0      100.0        1.55        1.71\n",
       "3  0.10  30   100.0      100.0        1.56        1.77\n",
       "4  0.05  30   100.0      100.0        1.58        1.80\n",
       "5  0.25  30   100.0      100.0        1.60        1.77\n",
       "6  0.20  30   100.0      100.0        1.65        2.06\n",
       "7  0.00  30   100.0      100.0        2.06        2.88"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random, time, statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Use your best tuned params\n",
    "TOP_CODES = 15\n",
    "K_NEIGHBORS = 40\n",
    "ALPHA = 0.65\n",
    "\n",
    "def retrieve_codes_with_beta(symptoms: str, beta: float) -> list[str]:\n",
    "    t = normalize_text(symptoms)\n",
    "    if not t.strip():\n",
    "        freq = Counter(doc_gt)\n",
    "        return [c for c, _ in freq.most_common(TOP_CODES) if c]\n",
    "\n",
    "    qw = word_vec.transform([t])\n",
    "    qc = char_vec.transform([t])\n",
    "\n",
    "    sw = (word_X @ qw.T).toarray().ravel()\n",
    "    sc = (char_X @ qc.T).toarray().ravel()\n",
    "    s = ALPHA * sw + (1.0 - ALPHA) * sc\n",
    "\n",
    "    k = min(K_NEIGHBORS, len(s))\n",
    "    idx = np.argpartition(-s, k - 1)[:k]\n",
    "    idx = idx[np.argsort(-s[idx])]\n",
    "\n",
    "    code_score = defaultdict(float)\n",
    "    for rank, i in enumerate(idx, start=1):\n",
    "        w = float(s[i]) / rank\n",
    "\n",
    "        gt = str(doc_gt[i]).strip()\n",
    "        if gt:\n",
    "            code_score[gt] += w\n",
    "\n",
    "        for code in doc_valid[i]:\n",
    "            code = str(code).strip()\n",
    "            if code and code != gt:\n",
    "                code_score[code] += beta * w\n",
    "\n",
    "    best = sorted(code_score.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [c for c, _ in best[:TOP_CODES]] if best else []\n",
    "\n",
    "def eval_beta(subset, beta: float) -> dict:\n",
    "    acc1 = 0\n",
    "    rec3 = 0\n",
    "    lat = []\n",
    "\n",
    "    for r in subset:\n",
    "        q = r.get(\"query\", \"\")\n",
    "        gt = str(r.get(\"gt\", \"\"))\n",
    "        valid = set(r.get(\"icd_codes\", []))\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        preds = retrieve_codes_with_beta(q, beta)\n",
    "        lat.append(time.perf_counter() - t0)\n",
    "\n",
    "        top3 = preds[:3]\n",
    "        if top3 and top3[0] == gt:\n",
    "            acc1 += 1\n",
    "        if any(c in valid for c in top3):\n",
    "            rec3 += 1\n",
    "\n",
    "    n = len(subset) or 1\n",
    "    lat_sorted = sorted(lat)\n",
    "    p95 = lat_sorted[int(0.95 * (len(lat_sorted) - 1))] if lat_sorted else None\n",
    "\n",
    "    return {\n",
    "        \"beta\": beta,\n",
    "        \"n\": len(subset),\n",
    "        \"acc1_%\": round(100 * acc1 / n, 2),\n",
    "        \"recall3_%\": round(100 * rec3 / n, 2),\n",
    "        \"lat_avg_ms\": round(1000 * statistics.mean(lat), 2),\n",
    "        \"lat_p95_ms\": round(1000 * p95, 2) if p95 is not None else None,\n",
    "    }\n",
    "\n",
    "# Random subset\n",
    "seed = 123\n",
    "rng = random.Random(seed)\n",
    "subset = records[:]\n",
    "rng.shuffle(subset)\n",
    "subset = subset[:min(30, len(subset))]\n",
    "print(\"Subset size:\", len(subset), \"seed:\", seed)\n",
    "\n",
    "betas = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "rows = [eval_beta(subset, b) for b in betas]\n",
    "\n",
    "df_beta = pd.DataFrame(rows).sort_values(\n",
    "    by=[\"recall3_%\", \"acc1_%\", \"lat_avg_ms\"],\n",
    "    ascending=[False, False, True],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8674b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset size: 50 seed: 123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>n</th>\n",
       "      <th>acc1_%</th>\n",
       "      <th>recall3_%</th>\n",
       "      <th>lat_avg_ms</th>\n",
       "      <th>lat_p95_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>50</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>50</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>50</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.40</td>\n",
       "      <td>50</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.30</td>\n",
       "      <td>50</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>50</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beta   n  acc1_%  recall3_%  lat_avg_ms  lat_p95_ms\n",
       "0  0.05  50   100.0      100.0        1.57        1.77\n",
       "1  0.10  50   100.0      100.0        1.58        1.75\n",
       "2  0.20  50   100.0      100.0        1.58        1.77\n",
       "3  0.15  50   100.0      100.0        1.61        1.81\n",
       "4  0.25  50   100.0      100.0        1.61        1.82\n",
       "5  0.40  50   100.0      100.0        1.61        1.81\n",
       "6  0.30  50   100.0      100.0        1.62        1.81\n",
       "7  0.00  50   100.0      100.0        2.20        4.28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random, time, statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Use your best tuned params\n",
    "TOP_CODES = 15\n",
    "K_NEIGHBORS = 40\n",
    "ALPHA = 0.65\n",
    "\n",
    "def retrieve_codes_with_beta(symptoms: str, beta: float) -> list[str]:\n",
    "    t = normalize_text(symptoms)\n",
    "    if not t.strip():\n",
    "        freq = Counter(doc_gt)\n",
    "        return [c for c, _ in freq.most_common(TOP_CODES) if c]\n",
    "\n",
    "    qw = word_vec.transform([t])\n",
    "    qc = char_vec.transform([t])\n",
    "\n",
    "    sw = (word_X @ qw.T).toarray().ravel()\n",
    "    sc = (char_X @ qc.T).toarray().ravel()\n",
    "    s = ALPHA * sw + (1.0 - ALPHA) * sc\n",
    "\n",
    "    k = min(K_NEIGHBORS, len(s))\n",
    "    idx = np.argpartition(-s, k - 1)[:k]\n",
    "    idx = idx[np.argsort(-s[idx])]\n",
    "\n",
    "    code_score = defaultdict(float)\n",
    "    for rank, i in enumerate(idx, start=1):\n",
    "        w = float(s[i]) / rank\n",
    "\n",
    "        gt = str(doc_gt[i]).strip()\n",
    "        if gt:\n",
    "            code_score[gt] += w\n",
    "\n",
    "        for code in doc_valid[i]:\n",
    "            code = str(code).strip()\n",
    "            if code and code != gt:\n",
    "                code_score[code] += beta * w\n",
    "\n",
    "    best = sorted(code_score.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [c for c, _ in best[:TOP_CODES]] if best else []\n",
    "\n",
    "def eval_beta(subset, beta: float) -> dict:\n",
    "    acc1 = 0\n",
    "    rec3 = 0\n",
    "    lat = []\n",
    "\n",
    "    for r in subset:\n",
    "        q = r.get(\"query\", \"\")\n",
    "        gt = str(r.get(\"gt\", \"\"))\n",
    "        valid = set(r.get(\"icd_codes\", []))\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        preds = retrieve_codes_with_beta(q, beta)\n",
    "        lat.append(time.perf_counter() - t0)\n",
    "\n",
    "        top3 = preds[:3]\n",
    "        if top3 and top3[0] == gt:\n",
    "            acc1 += 1\n",
    "        if any(c in valid for c in top3):\n",
    "            rec3 += 1\n",
    "\n",
    "    n = len(subset) or 1\n",
    "    lat_sorted = sorted(lat)\n",
    "    p95 = lat_sorted[int(0.95 * (len(lat_sorted) - 1))] if lat_sorted else None\n",
    "\n",
    "    return {\n",
    "        \"beta\": beta,\n",
    "        \"n\": len(subset),\n",
    "        \"acc1_%\": round(100 * acc1 / n, 2),\n",
    "        \"recall3_%\": round(100 * rec3 / n, 2),\n",
    "        \"lat_avg_ms\": round(1000 * statistics.mean(lat), 2),\n",
    "        \"lat_p95_ms\": round(1000 * p95, 2) if p95 is not None else None,\n",
    "    }\n",
    "\n",
    "# Random subset\n",
    "seed = 123\n",
    "rng = random.Random(seed)\n",
    "subset = records[:]\n",
    "rng.shuffle(subset)\n",
    "subset = subset[:min(50, len(subset))]\n",
    "print(\"Subset size:\", len(subset), \"seed:\", seed)\n",
    "\n",
    "betas = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "rows = [eval_beta(subset, b) for b in betas]\n",
    "\n",
    "df_beta = pd.DataFrame(rows).sort_values(\n",
    "    by=[\"recall3_%\", \"acc1_%\", \"lat_avg_ms\"],\n",
    "    ascending=[False, False, True],\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62bd6aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/dana/Desktop/qazcode/qazcode-nu/data\n",
      "Has src here? False\n",
      "Has data here? False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Has src here?\", (Path.cwd() / \"src\").exists())\n",
    "print(\"Has data here?\", (Path.cwd() / \"data\").exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d6f8be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dana/Desktop/qazcode/qazcode-nu/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e51c53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/dana/Desktop/qazcode/qazcode-nu\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "os.chdir(\"..\")  # go from .../data to .../qazcode-nu\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "sys.path.insert(0, os.getcwd())  # so Python can import src.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d27c2c3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ROOT = \u001b[43mfind_root\u001b[49m()\n\u001b[32m      5\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(ROOT / \u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m))  \u001b[38;5;66;03m# add src/ itself\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmock_server\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mms\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'find_root' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = find_root()\n",
    "sys.path.insert(0, str(ROOT / \"src\"))  # add src/ itself\n",
    "import mock_server as ms\n",
    "ms.build_protocol_index()\n",
    "print(\"Imported from:\", ms.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce75a747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoaded:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tests))\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2) Use the EXACT same retriever as the mock server\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mock_server \u001b[38;5;28;01mas\u001b[39;00m ms\n\u001b[32m     11\u001b[39m ms.build_protocol_index()  \u001b[38;5;66;03m# uses your updated focused indexing if you patched it\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnorm_code\u001b[39m(x):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import json, time, statistics, re\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Load test set\n",
    "TEST_DIR = Path(\"data/test_set\")\n",
    "tests = [json.loads(p.read_text(encoding=\"utf-8\")) for p in sorted(TEST_DIR.glob(\"*.json\"))]\n",
    "print(\"Loaded:\", len(tests))\n",
    "\n",
    "# 2) Use the EXACT same retriever as the mock server\n",
    "from src import mock_server as ms\n",
    "ms.build_protocol_index()  # uses your updated focused indexing if you patched it\n",
    "\n",
    "def norm_code(x):\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    s = str(x).strip().upper()\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "acc1 = 0\n",
    "rec3 = 0\n",
    "lat = []\n",
    "\n",
    "for t in tests:\n",
    "    q = t.get(\"query\", \"\")\n",
    "    gt = norm_code(t.get(\"gt\", \"\"))\n",
    "    valid = {norm_code(c) for c in (t.get(\"icd_codes\", []) or [])}\n",
    "    if gt:\n",
    "        valid.add(gt)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    codes, _ = ms.retrieve_codes_from_protocols(\n",
    "        q, top_codes=15, k_neighbors=40, alpha=0.65, beta=0.15\n",
    "    )\n",
    "    lat.append(time.perf_counter() - t0)\n",
    "\n",
    "    top3 = [norm_code(c) for c in (codes[:3] if codes else [])]\n",
    "\n",
    "    if top3 and top3[0] in valid:\n",
    "        acc1 += 1\n",
    "    if any(c in valid for c in top3):\n",
    "        rec3 += 1\n",
    "\n",
    "n = len(tests) or 1\n",
    "lat_sorted = sorted(lat)\n",
    "p95 = lat_sorted[int(0.95*(n-1))] if lat_sorted else None\n",
    "\n",
    "print({\n",
    "    \"n\": len(tests),\n",
    "    \"accuracy@1_%\": round(100*acc1/n, 2),\n",
    "    \"recall@3_%\": round(100*rec3/n, 2),\n",
    "    \"lat_avg_ms\": round(1000*statistics.mean(lat), 2),\n",
    "    \"lat_p95_ms\": round(1000*p95, 2) if p95 is not None else None,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed0324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qazcode-nu (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
